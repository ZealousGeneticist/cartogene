{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "##############################################\n",
    "#  Cartogene:                                #\n",
    "#  Brief description of what this code does  #\n",
    "#                                            #\n",
    "# First Write: 02/01/2023                    #\n",
    "# Last Visit: 10/25/2023                     #\n",
    "#                                            #\n",
    "# Luke Mabry <elmabry99@gmail.com>           #\n",
    "# License: GPL v3.0                          #\n",
    "##############################################\n",
    "\n",
    "#Package Installation\n",
    "import subprocess\n",
    "import sys\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "install(\"requests\")\n",
    "import requests, json, time, math, os, argparse\n",
    "install(\"pandas\")\n",
    "import pandas as pd\n",
    "install(\"str2bool\")\n",
    "from str2bool import str2bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15283b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###USER DEFINED VARIABLES###\n",
    "##################################\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "#infile, Input Chemical List\n",
    "parser.add_argument(\"-i\", \"--input\", required=True,\n",
    "                    help=\"input file name of chemical list\")\n",
    "\n",
    "#outfile3, Edge List Name\n",
    "parser.add_argument(\"-o\", \"--output\", required=False,\n",
    "                    nargs='?', default=\"faceted_inact_node_network.tsv\", const=\"faceted_inact_node_network.tsv\",\n",
    "                    help=\"ouput edge list file name\\ndefault='faceted_inact_node_network.tsv'\")\n",
    "\n",
    "#outfile1, CTD Chemical-Gene Interaction Table Name\n",
    "parser.add_argument(\"-c\", \"--ctd\", required=False,\n",
    "                    nargs='?', default=\"interactionsCTD\", const=\"interactionsCTD\",\n",
    "                    help=\"CTD chemical-gene interaction file name\\ndefault='interactionsCTD'\")\n",
    "\n",
    "#outjson, IntAct (Large) Data File Name\n",
    "parser.add_argument(\"-j\", \"--json\", required=False,\n",
    "                    nargs='?', default=\"faceted_intact_results\", const=\"faceted_intact_results\",\n",
    "                    help=\"large orginal IntAct data file name\\ndefault='faceted_intact_results'\")\n",
    "\n",
    "#organismID, NCBI Taxonomy Number\n",
    "parser.add_argument(\"-g\", \"--organism\", required=False,\n",
    "                    nargs='?', default=9606, const=9606, \n",
    "                    type=int,\n",
    "                    help=\"organism NCBI Taxonomy ID number\\ndefault=9606\")\n",
    "\n",
    "#test, Omniscience Specific Single-Data-File Tester\n",
    "parser.add_argument(\"-t\", \"--test\", required=False,\n",
    "                    nargs='?', default=False, const=False,\n",
    "                    help=\"Used to output only one IntAct JSON to test computing problems\\ndefault=False\")\n",
    "\n",
    "#debug\n",
    "parser.add_argument(\"-d\", \"--debug\", required=False,\n",
    "                    nargs='?', default=False, const=False,\n",
    "                    help=\"debug mode\\ndefault=False\")\n",
    "\n",
    "#removeJSON, Deletes orginal data JSON in cleanup\n",
    "parser.add_argument(\"-r\", \"--removejson\", required=False,\n",
    "                    nargs='?', default=True, const=True,\n",
    "                    help=\"cleanup option, set to False to disable\\ndefault=True\")\n",
    "\n",
    "#outputHeader, Edge List (outfile3) Header Enable/Disable\n",
    "parser.add_argument(\"-e\", \"--header\", required=False,\n",
    "                    nargs='?', default=False, const=False,\n",
    "                    help=\"header option for the final edge list\\ncalled '-e' because '-h' is help\\ndeafult=False\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "##################################\n",
    "\n",
    "#Define Input and Output Files\n",
    "infile = args.input\n",
    "outfile3 = args.output\n",
    "outfile1 = args.ctd\n",
    "outjson = args.json\n",
    "organism= args.organism #Define Taxonomy ID\n",
    "test = str2bool(str(args.test)) #Omniscience function toggle for single file output\n",
    "debug = str2bool(str(args.debug)) #Debugging toggle for verbose output\n",
    "removeJSON = str2bool(str(args.removejson)) #Toggle for deleting orginal IntAct JSON file\n",
    "outputHeader = str2bool(str(args.header)) #Toggle for having headers in the final node library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325f8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "###USER DEFINED FUNCTIONS###\n",
    "\n",
    "##Take data of bioactive compounds and ask for what they interact with in homo sapiens\n",
    "#Retrieve data via CTD's batch Querry Tool, send an HTTP GET request to http://ctdbase.org/tools/batchQuery.go\n",
    "\n",
    "#Define the program to easily request data from chems and other types of data\n",
    "def cgixns(infile, outfile1, inputType='chem', actionTypes='ANY', debug=False):\n",
    "    print('Begining Comparative Toxicogenomics Database (CTD) chemical-gene interaction Batch Query...')\n",
    "    with open(infile, 'r') as lines:\n",
    "        inTerms = lines.read()\n",
    "    #CTD URL Batch Querry with input\n",
    "    url = 'http://ctdbase.org/tools/batchQuery.go?report=cgixns&format=tsv&inputTerms='\n",
    "    get = requests.get(url+inTerms+'&'+'inputType='+inputType+'&'+'actionTypes='+actionTypes)\n",
    "    #Save interaction data in outfile1\n",
    "    with open(outfile1+'_chemical-protein.tsv', 'wb') as b:\n",
    "        b.write(get.content)\n",
    "    #Set debug=True if making/editing code\n",
    "    if debug:\n",
    "        print(inTerms)\n",
    "        print(type(get))\n",
    "        print(f\"{get.status_code}: {get.reason}\")\n",
    "        with open(infile, 'rb') as lines:\n",
    "            print(lines.read())\n",
    "    return print(\"Done with chemical to gene interactions! Have a great rest of your research, dude! :)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define program to grab all interaction data from IntAct on all genes in CTD Data from cgixns as omniscience\n",
    "def omniscience(outfile1, outjson, jsonSize=10_000, organism=9606, test=False, debug=False):\n",
    "    print('Beginning to grab all interaction data from IntAct on all genes in CTD datatable...')\n",
    "    ###Define function to take outfile1 dataframe and get all interactions between genes\n",
    "    #Don't need to make them connect yet with chemicals.\n",
    "\n",
    "    ##Turn outfile1 into a dataframe with pandas\n",
    "    of1df = pd.read_table(outfile1+'_chemical-protein.tsv') #outfile1 dataframe code\n",
    "    #Select for only human data (assuming human); haa stands for \"I'm only Human, After All\" (its a meme)\n",
    "    haa = of1df[of1df[\"OrganismID\"] == organism]\n",
    "    #debug\n",
    "    if debug:\n",
    "        print(of1df.head(3))\n",
    "        print('\\n\\nNext Table\\n\\n')\n",
    "        print(haa.head(3))\n",
    "    ##select for 5th column values, the genesymbols, and save as a list & string\n",
    "    genesymbols = haa[\"GeneSymbol\"].drop_duplicates(keep='first')\n",
    "    gsl = genesymbols.to_list() #genesymbols list variable = gsl\n",
    "    gss = ''\n",
    "    for name in gsl:\n",
    "        if gss == '':\n",
    "            gss += name\n",
    "        else:\n",
    "                gss += ' '+name\n",
    "    #debug\n",
    "    if debug:\n",
    "        print(gss[0:20])\n",
    "        print(gsl[0:5])\n",
    "\n",
    "    ##Script to querry for all gene products interactions with the above bioactive compounds\n",
    "    #Search for interactions with findInteractionWithFacet on IntAct Advanced Search with gss\n",
    "    url_facet = 'https://www.ebi.ac.uk/intact/ws/interaction/findInteractionWithFacet?'\n",
    "    #The Parameters\n",
    "    query = f\"taxidA:({organism}) AND taxidB:({organism}) AND geneName:({gss}) AND ((ptypeA:protein) AND (ptypeB:protein))\"\n",
    "    # (((ptypeA:protein) OR (ptypeA:gene)) AND ((ptypeB:protein) OR (ptypeB:gene)))\n",
    "    pm = {\"advancedSearch\" : True, \"intraSpeciesFilter\":True, \"page\": 0, \"pageSize\": 1, \"query\":query}\n",
    "    post = requests.post(url_facet,params=pm)\n",
    "    i = 0\n",
    "    totalele= post.json()['data']['totalElements']\n",
    "    filenum = math.ceil(totalele / jsonSize)\n",
    "    #Omniscience feedback#\n",
    "    print('The number of elements in total:',totalele)\n",
    "    del totalele\n",
    "    if ~test:\n",
    "        print(\"The number of files shall be:\",filenum)\n",
    "        print('Omniscience prepped. Beginning to write file: \\n',(i+1),\"of\",filenum)\n",
    "    else:\n",
    "        print(\"Since this is a test, there will only be 1 file; normally, the number of files would be:\", filenum)\n",
    "        print('Omniscience prepped.')\n",
    "    pm['pageSize'] = jsonSize\n",
    "    del post\n",
    "    #Estimate Time for each file to download from server\n",
    "    print('The server will take about',requests.post(url_facet,params=pm).elapsed,'to process each file.\\n')\n",
    "\n",
    "    ###Save interactions data json in folder as outfile2\n",
    "    #Option to only make 1 file, then fake files to see if the procedure works\n",
    "    if test:\n",
    "        if debug:\n",
    "            print('The # of pages is',filenum)\n",
    "        while i < filenum:\n",
    "            if debug:\n",
    "                print('The # of pages is still',filenum)\n",
    "            i += 1\n",
    "            pm['page'] = i\n",
    "            outfile2 = outjson + str(i) + '.json'\n",
    "            print('Saving...')\n",
    "            with open(outfile2, 'w') as f:\n",
    "                #Making a json for testing with reductionism\n",
    "                f.write('{\"data\":{\"content\":[{\"moleculeA\":\"IMITA\",\"moleculeB\":\"TION\"}]}}')\n",
    "            print('Saved imitation file-',i,'.\\n')\n",
    "            time.sleep(1)\n",
    "    else:\n",
    "        if debug:\n",
    "            print('The # of pages is',filenum)\n",
    "        while i < filenum:\n",
    "            pm['page'] = i\n",
    "            outfile2 = outjson +'_'+ str(i) + '_PPI.json'\n",
    "            print('Saving...')\n",
    "            with open(outfile2, 'wb') as f:\n",
    "                for chunk in requests.post(url_facet,params=pm).iter_content(chunk_size=4096):\n",
    "                    f.write(chunk)\n",
    "            print('File',i+1,'saved.\\n')\n",
    "            i += 1\n",
    "            time.sleep(1)\n",
    "    #Exiting Messages\n",
    "    print('Omniscience complete. \\n',i,'file(s) have been blessed upon you.')\n",
    "    print('The sciences shall voyage far from our island of ignorance into the midst of black seas of infinity.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7923f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Make an edge network of source nodes and target nodes (whether chemical or gene)\n",
    "def reductionism(outfile1, outjson, outfile3, outputHeader=True, organism=9606, debug = False):\n",
    "    print('Oh yeah, reductionism time...\\n Please wait...')\n",
    "    ###Pull out from content moleculeA, moleculeB and add an edgeLabel for PPI\n",
    "    def nodepull(b,x=[],y=[]):\n",
    "        for a in json.load(b)['data']['content']:\n",
    "            x.append(a['moleculeA'])\n",
    "            y.append(a['moleculeB'])\n",
    "\n",
    "    #Define function to sort by row then by column alphanumerically to remove duplicate edges (a-b == b-a)\n",
    "    def dupeRemove(nodeA,nodeB,edgeLabel = ''):\n",
    "        #Put Node list into a dataframe\n",
    "        nodes = {'nodeA':nodeA,\n",
    "                'nodeB':nodeB}\n",
    "        nodedf = pd.DataFrame(nodes)\n",
    "        ##Sort by row then by column alphanumerically to remove duplicate edges (a-b == b-a)\n",
    "        nodesort = nodedf.values\n",
    "        nodesort.sort(axis=1)\n",
    "        nodedf = pd.DataFrame(nodesort, nodedf.index, nodedf.columns)\n",
    "        nodedf = nodedf.sort_values(by='nodeA')\n",
    "        nodedf = nodedf.drop_duplicates(keep='first')\n",
    "        #For applying edgeLabel to each set of nodes\n",
    "        edgeList = [] \n",
    "        for x in nodeA:\n",
    "                edgeList.append(edgeLabel)\n",
    "        nodedf['edgeType'] = edgeLabel\n",
    "        return nodedf\n",
    "\n",
    "    #Pull up every outjson file and use for edge table\n",
    "    nodesSource = []\n",
    "    nodesTarget = []\n",
    "    with os.scandir() as directory:\n",
    "        for item in directory:\n",
    "            if item.name.startswith(outjson) and item.name.endswith('_PPI.json') and item.is_file():\n",
    "                with open(item,'rb') as b:\n",
    "                    nodepull(b,nodesSource,nodesTarget) #NOTE, should replace later because opening each json is bad\n",
    "                    print(item.name, 'is done being reduced!')\n",
    "    \n",
    "    ##Put edge table for input chemicals in\n",
    "    node1 = []\n",
    "    node2 = []\n",
    "    of1df = pd.read_table(outfile1+'_chemical-protein.tsv') #outfile1 dataframe code\n",
    "    #Select for only human data(assuming human); haa stands for \"I'm only Human, After All\" (its a meme)\n",
    "    haa = of1df[of1df[\"OrganismID\"] == organism]\n",
    "    ##select for 4th column values, the chemicalName, and save as a list & string\n",
    "    chemicalName = haa[[\"ChemicalName\",\"GeneSymbol\"]].drop_duplicates(keep='first')\n",
    "    for a in chemicalName.ChemicalName.to_list():\n",
    "        node1.append(a)\n",
    "    for a in chemicalName.GeneSymbol.to_list():\n",
    "        node2.append(a)\n",
    "\n",
    "    #Put Node list into node library\n",
    "    x = dupeRemove(nodesSource,nodesTarget,'PPI')\n",
    "    y = dupeRemove(node1,node2,'chemical-protein')\n",
    "    finaldf = pd.concat([x,y],ignore_index=True) #Joining the dataFrames together\n",
    "    #debug\n",
    "    if debug:\n",
    "        print(finaldf)\n",
    "\n",
    "    #Comes down to a 2 column dataframe in outfile3, input for outputHeader\n",
    "    finaldf.to_csv(outfile3, index=False, sep='\\t', header= outputHeader)\n",
    "    print('Reduced to atoms... or at least: \\n',os.stat(outfile3).st_size/1000, 'kB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eee028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for deleting huge JSON files from omniscience as cleanup\n",
    "def cleanup(removeJSON):\n",
    "    if removeJSON:\n",
    "        with os.scandir() as directory:\n",
    "            for item in directory:\n",
    "                if item.name.startswith(outjson) and item.name.endswith('_PPI.json') and item.is_file():\n",
    "                    os.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2cf382",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROGRAM ###\n",
    "print('\\n\\n\\n')\n",
    "cgixns(infile, outfile1 ,actionTypes='binding')\n",
    "omniscience(outfile1, outjson)\n",
    "reductionism(outfile1,outjson,outfile3,outputHeader)\n",
    "cleanup(removeJSON)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
